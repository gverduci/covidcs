# This is a basic workflow ...

name: Scrape data

# Controls when the workflow will run
on:
  # Triggers the workflow on cron
  schedule:
    - cron:  '00 21 * * *'
  # Allows you to run this workflow manually from the Actions tab
  # workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "scrape-data"
  scrape-data:
    # Name of the Job
    name: Scrape data
    # Set the type of machine to run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install libxml libxslt
        run: sudo apt-get install libxml2-dev libxslt-dev python-dev

      # Set up Python
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # Install dependencies from requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      # Get data
      - name: Get data
        run: ./runall.sh

      # Commit & Push
      - name: Commit a new report (if necessary)
        run: |
          echo "Checking data on: `date`"
          if [ -n "$(git status --porcelain)" ]; then
            echo "New update available"
            git config --global user.name 'GitHub Actions'
            git config --global user.email '41898282+github-actions[bot]@users.noreply.github.com'
            git add .
            git commit -am "Add new reports"
            git push
          else
            echo "no changes to commit"
          fi
        env:
          TZ: Europe/Rome
